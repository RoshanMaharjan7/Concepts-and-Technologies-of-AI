{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RoshanMaharjan7/Concepts-and-Technologies-of-AI/blob/main/Roshan_Maharjan_2408424_Worksheet8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ensemble Methods and Hyperparameter Tuning."
      ],
      "metadata": {
        "id": "kewmx_J7JMUl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1. Implement Classification Models:**\n",
        "\n",
        "• Train a Decision Tree Classifier and a Random Forest Classifier using scikit-learn.\n",
        "\n",
        "• Compare the models based on their F1 scores."
      ],
      "metadata": {
        "id": "i0vBV-ofJUZb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_wine\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "wine = load_wine()\n",
        "X, y = wine.data, wine.target\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "z-WIsOhpLThh"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "dt_classifier = DecisionTreeClassifier(random_state=42)\n",
        "dt_classifier.fit(X_train, y_train)\n",
        "y_pred_dt = dt_classifier.predict(X_test)\n",
        "f1_dt = f1_score(y_test, y_pred_dt, average='weighted')\n",
        "print(f\"Decision Tree F1 Score: {f1_dt:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X5viqSnYLixL",
        "outputId": "6e193c1d-11b9-4881-bc8c-ac296f97a8bf"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decision Tree F1 Score: 0.9440\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "rf_classifier = RandomForestClassifier(random_state=42)\n",
        "rf_classifier.fit(X_train, y_train)\n",
        "y_pred_rf = rf_classifier.predict(X_test)\n",
        "f1_rf = f1_score(y_test, y_pred_rf, average='weighted')\n",
        "print(f\"Random Forest F1 Score: {f1_rf:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l7AU0nYGLrQl",
        "outputId": "f9f10af9-e3c7-4d3f-9b53-c2a5fe0246ba"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest F1 Score: 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2. Hyperparameter Tuning:**\n",
        "\n",
        "• Identify three hyperparameters of the Random Forest Classifier.\n",
        "\n",
        "• Perform hyperparameter tuning using GridSearchCV to optimize these parameters.\n",
        "\n",
        "• Take hints from the scikit-learn documentation to guide the implementation."
      ],
      "metadata": {
        "id": "hQFH9G7HJY4r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "param_grid = {\n",
        "    'n_estimators': [50, 100, 200],\n",
        "    'max_depth': [None, 5, 10],\n",
        "    'min_samples_split': [2, 5, 10]\n",
        "}\n",
        "\n",
        "grid_search = GridSearchCV(estimator=rf_classifier, param_grid=param_grid, cv=5, scoring='f1_weighted')\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "print(\"Best Parameters:\", grid_search.best_params_)\n",
        "print(\"Best F1 Score:\", grid_search.best_score_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LHdUl6ydLz3f",
        "outputId": "cbafc52f-9684-44f2-b3c4-fe5860b1176a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Parameters: {'max_depth': None, 'min_samples_split': 2, 'n_estimators': 100}\n",
            "Best F1 Score: 0.9782952128219708\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3. Implement Regression Model:**\n",
        "\n",
        "• Train a Decision Tree Regressor and a Random Forest Regressor using scikit-learn.\n",
        "\n",
        "• Identify three parameters for Random Forest Regressio and Perform hyperparameter tuning using\n",
        "RandomSearchCV to optimize these parameters."
      ],
      "metadata": {
        "id": "4WEkvJZMJcq5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4QOErozLI5mf",
        "outputId": "24581adc-7b25-4a36-bf72-5420f59cb63e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decision Tree Regressor MSE: 0.1667\n",
            "Random Forest Regressor MSE: 0.0648\n",
            "Best Hyperparameters: {'n_estimators': 200, 'min_samples_split': 10, 'max_depth': 30}\n",
            "Best MSE: 0.0468\n"
          ]
        }
      ],
      "source": [
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "#Train a Decision Tree Regressor\n",
        "dt_regressor = DecisionTreeRegressor(random_state=42)\n",
        "dt_regressor.fit(X_train, y_train)\n",
        "y_pred_dt_reg = dt_regressor.predict(X_test)\n",
        "mse_dt_reg = mean_squared_error(y_test, y_pred_dt_reg)\n",
        "\n",
        "#Train a Random Forest Regressor\n",
        "rf_regressor = RandomForestRegressor(random_state=42)\n",
        "rf_regressor.fit(X_train, y_train)\n",
        "y_pred_rf_reg = rf_regressor.predict(X_test)\n",
        "mse_rf_reg = mean_squared_error(y_test, y_pred_rf_reg)\n",
        "\n",
        "print(f\"Decision Tree Regressor MSE: {mse_dt_reg:.4f}\")\n",
        "print(f\"Random Forest Regressor MSE: {mse_rf_reg:.4f}\")\n",
        "\n",
        "#Define the hyperparameters to tune for Random Forest Regressor\n",
        "param_dist = {\n",
        "    'n_estimators': [50, 100, 200],\n",
        "    'max_depth': [None, 10, 20, 30],\n",
        "    'min_samples_split': [2, 5, 10]\n",
        "}\n",
        "\n",
        "#Perform RandomizedSearchCV to find the best hyperparameters\n",
        "random_search = RandomizedSearchCV(estimator=rf_regressor, param_distributions=param_dist, n_iter=10, cv=5, scoring='neg_mean_squared_error', random_state=42)\n",
        "random_search.fit(X_train, y_train)\n",
        "\n",
        "print(f\"Best Hyperparameters: {random_search.best_params_}\")\n",
        "print(f\"Best MSE: {-random_search.best_score_:.4f}\")"
      ]
    }
  ]
}